{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Named Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data ingestion, we have to specify these many configurations\n",
    "\n",
    "# Download Url\n",
    "# Download folder (compressed file)\n",
    "# Extract Folder ( Extracted file)\n",
    "# Train dataset folder\n",
    "# Test dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config. of source data\n",
    "DataIngestionConfig = namedtuple(\"DataIngestionConfig\", \n",
    "[\"dataset_download_url\", \"tgz_download_dir\", \"raw_data_dir\", \"ingested_train_dir\", \"ingested_test_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ingestion_config = DataIngestionConfig(dataset_download_url=\"demo\",\n",
    "tgz_download_dir=\"demo\",\n",
    "raw_data_dir=\"demo\",\n",
    "ingested_train_dir=\"demo\",\n",
    "ingested_test_dir=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionConfig(dataset_download_url='demo', tgz_download_dir='demo', raw_data_dir='demo', ingested_train_dir='demo', ingested_test_dir='demo')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now this is a named tuple where we can see what information is saved in what variable (name)\n",
    "# now this config cant be changed\n",
    "data_ingestion_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read .yaml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ\\\\notebook'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# to check the current location of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to locate that yaml file, so first step is to change the directory\n",
    "os.chdir(\"c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.dockerignore',\n",
       " '.git',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.vscode',\n",
       " 'app.py',\n",
       " 'build',\n",
       " 'config',\n",
       " 'dist',\n",
       " 'Dockerfile',\n",
       " 'housing',\n",
       " 'Housing_Logs',\n",
       " 'housinig_predictor.egg-info',\n",
       " 'Initial Steps Done.txt',\n",
       " 'LICENSE',\n",
       " 'notebook',\n",
       " 'Project Structure.png',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'setup.py',\n",
       " 'venv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check files of current directory\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config\\\\config.yaml'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a file path for yaml file\n",
    "\n",
    "# this os join makes file path accoriding to our operating system dynamically\n",
    "config_file_path = os.path.join(\"config\", \"config.yaml\")\n",
    "config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check if file is available or not\n",
    "os.path.exists(config_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening yaml file\n",
    "config_info = None\n",
    "with open(config_file_path, \"rb\") as yaml_file:\n",
    "    config_info = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_pipeline_config': {'pipeline_name': 'housing',\n",
       "  'artifact_dir': 'artifact'},\n",
       " 'data_ingestion_config': {'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       "  'raw_data_dir': 'raw_data',\n",
       "  'tgz_download_dir': 'tgz_data',\n",
       "  'ingested_dir': 'ingested_data',\n",
       "  'ingested_train_dir': 'train',\n",
       "  'ingested_test_dir': 'test'},\n",
       " 'data_validation_config': {'schema_dir': 'config',\n",
       "  'schema_file_name': 'schema.yaml',\n",
       "  'report_file_name': 'report.json',\n",
       "  'report_page_file_name': 'report.html'},\n",
       " 'data_transformation_config': {'add_bedroom_per_room': True,\n",
       "  'transformed_dir': 'transformed_data',\n",
       "  'transformed_train_dir': 'train',\n",
       "  'transformed_test_dir': 'test',\n",
       "  'preprocessing_dir': 'preprocessed',\n",
       "  'preprocessed_object_file_name': 'preprocessed.pkl'},\n",
       " 'model_trainer_config': {'trained_model_dir': 'trained_model',\n",
       "  'model_file_name': 'model.pkl',\n",
       "  'base_accuracy': 0.6,\n",
       "  'model_config_dir': 'config',\n",
       "  'model_config_file_name': 'model.yaml'},\n",
       " 'model_evaluation_config': {'model_evaluation_file_name': 'model_evaluation.yaml'},\n",
       " 'model_pusher_config': {'model_export_dir': 'saved_models'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a function to read yaml file\n",
    "\n",
    "from tkinter import E\n",
    "\n",
    "\n",
    "def read_yaml_file(file_path : str) -> dict:\n",
    "    \"\"\"\n",
    "    Reads a YAML file and returns the contents as a dictionart.\n",
    "    file_path : str\n",
    "    \"\"\"\n",
    "\n",
    "    try : \n",
    "        with open(file_path, 'rb') as yaml_file:\n",
    "            return yaml.safe_load(yaml_file)\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training_pipeline_config': {'pipeline_name': 'housing',\n",
       "  'artifact_dir': 'artifact'},\n",
       " 'data_ingestion_config': {'dataset_download_url': 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz',\n",
       "  'raw_data_dir': 'raw_data',\n",
       "  'tgz_download_dir': 'tgz_data',\n",
       "  'ingested_dir': 'ingested_data',\n",
       "  'ingested_train_dir': 'train',\n",
       "  'ingested_test_dir': 'test'},\n",
       " 'data_validation_config': {'schema_dir': 'config',\n",
       "  'schema_file_name': 'schema.yaml',\n",
       "  'report_file_name': 'report.json',\n",
       "  'report_page_file_name': 'report.html'},\n",
       " 'data_transformation_config': {'add_bedroom_per_room': True,\n",
       "  'transformed_dir': 'transformed_data',\n",
       "  'transformed_train_dir': 'train',\n",
       "  'transformed_test_dir': 'test',\n",
       "  'preprocessing_dir': 'preprocessed',\n",
       "  'preprocessed_object_file_name': 'preprocessed.pkl'},\n",
       " 'model_trainer_config': {'trained_model_dir': 'trained_model',\n",
       "  'model_file_name': 'model.pkl',\n",
       "  'base_accuracy': 0.6,\n",
       "  'model_config_dir': 'config',\n",
       "  'model_config_file_name': 'model.yaml'},\n",
       " 'model_evaluation_config': {'model_evaluation_file_name': 'model_evaluation.yaml'},\n",
       " 'model_pusher_config': {'model_export_dir': 'saved_models'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml = read_yaml_file(config_file_path)\n",
    "yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_pipeline_config'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PIPELINE_CONFIG_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### now we know that yaml reader returns output as dictionary, when we neeed to read value of this TRAINNG+PIPELINE_CONFIG_KEY, we can simply use it as its already hardcoded in constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_name': 'housing', 'artifact_dir': 'artifact'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml[TRAINING_PIPELINE_CONFIG_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifact_dir'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PIPELINE_ARTIFACT_DIR_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artifact_dir'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PIPELINE_ARTIFACT_DIR_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_pipeline_config'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PIPELINE_CONFIG_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipeline_name'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_PIPELINE_NAME_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# opening yaml file\n",
    "config_info = None\n",
    "with open(config_file_path, \"rb\") as yaml_file:\n",
    "    config_info = yaml.safe_load(yaml_file)\n",
    "\n",
    "training_pipeline_config = config_info[TRAINING_PIPELINE_CONFIG_KEY]\n",
    "artifact_dir = os.path.join(ROOT_DIR,\n",
    "                            training_pipeline_config[TRAINING_PIPELINE_NAME_KEY],\n",
    "                            training_pipeline_config[TRAINING_PIPELINE_ARTIFACT_DIR_KEY])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ\\\\housing\\\\artifact'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_name': 'housing', 'artifact_dir': 'artifact'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.entity.config_entity import TrainingPipelineConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trianing_pipeline_config = TrainingPipelineConfig(artifact_dir=artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingPipelineConfig(artifact_dir='c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ\\\\housing\\\\artifact')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trianing_pipeline_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking configuration.py : get_training_pipeline_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from housing.config.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making object of the class\n",
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingPipelineConfig(artifact_dir='c:\\\\Users\\\\rkt7k\\\\Desktop\\\\iNeuron Data Science\\\\Projects iNeuron\\\\MLPROJ\\\\housing\\\\artifact')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.get_training_pipeline_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00726805eb41b3255af9a27d95b8ce39facc52a3fc604138ebaaec17dd9f8017"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
